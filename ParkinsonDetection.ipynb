{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "os.chdir('D:/SEM 6/ML/PPMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:/SEM 6/ML/PPMI/Health_Control_nifti/PPMI/3000/AX_T2_FLAIR/2011-02-01_08_05_22.0/S102118/PPMI_3000_MR_AX_T2_FLAIR__br_raw_20110322143440789_17_S102118_I224561.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "img = nib.load(file_path)\n",
    "img_data = np.asanyarray(img.dataobj)\n",
    "img_data = np.resize(img_data, (256,256))\n",
    "print(img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "main1 = 'D:/SEM 6/ML/PPMI/Health_Control_nifti/PPMI'\n",
    "for sample in os.listdir(main1):\n",
    "  main2 = main1 + '/' + sample\n",
    "  for f1 in os.listdir(main2):\n",
    "    main3 = main2 + '/' + f1\n",
    "    for f2 in os.listdir(main3):\n",
    "      main4 = main3 + '/' + f2\n",
    "      for f3 in os.listdir(main4):\n",
    "        main5 = main4 + '/' + f3\n",
    "        for f4 in os.listdir(main5):\n",
    "            path = main5 + '/' + f4\n",
    "            img = nib.load(path)\n",
    "            img_data = np.asanyarray(img.dataobj)\n",
    "            img_data = np.resize(img_data, (256,256,3))\n",
    "            x.append(img_data)\n",
    "            y.append(0)\n",
    "            \n",
    "main1 = 'D:/SEM 6/ML/PPMI/PD_NiFTI/PPMI'\n",
    "for sample in os.listdir(main1):\n",
    "  main2 = main1 + '/' + sample\n",
    "  for f1 in os.listdir(main2):\n",
    "    main3 = main2 + '/' + f1\n",
    "    for f2 in os.listdir(main3):\n",
    "      main4 = main3 + '/' + f2\n",
    "      for f3 in os.listdir(main4):\n",
    "        main5 = main4 + '/' + f3\n",
    "        for f4 in os.listdir(main5):\n",
    "            path = main5 + '/' + f4\n",
    "            img = nib.load(path)\n",
    "            img_data = np.asanyarray(img.dataobj)\n",
    "            img_data = np.resize(img_data, (256,256,3))\n",
    "            x.append(img_data)\n",
    "            y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)   301\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape,\" \",len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(240, 256, 256, 3)\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.array(X_test).reshape(61, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (256,256,3)\n",
    "\n",
    "kernel_size = (2, 2)\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 255, 255, 32)      416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 255, 255, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3936320   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,949,762\n",
      "Trainable params: 3,949,506\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters, kernel_size, activation='softmax', input_shape=data_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters, kernel_size, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters*2, kernel_size, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 50  # Increase this value for better results (i.e., more training)\n",
    "batch_size = 30  # Increasing this value might speed up fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "240/240 [==============================] - 59s 247ms/step - loss: 0.6699 - accuracy: 0.7208\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6582 - accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6409 - accuracy: 0.7479\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6553 - accuracy: 0.7458\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.6412 - accuracy: 0.7479\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.6439 - accuracy: 0.7479\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6451 - accuracy: 0.7292\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.6444 - accuracy: 0.7250\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6420 - accuracy: 0.7208\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 57s 238ms/step - loss: 0.6318 - accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6311 - accuracy: 0.7458\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6256 - accuracy: 0.7292\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 59s 246ms/step - loss: 0.6349 - accuracy: 0.7375\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6330 - accuracy: 0.7542\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 58s 241ms/step - loss: 0.6233 - accuracy: 0.7417\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6127 - accuracy: 0.7250\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 58s 240ms/step - loss: 0.6379 - accuracy: 0.7083\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 58s 244ms/step - loss: 0.6027 - accuracy: 0.7667\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.6341 - accuracy: 0.7167\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 57s 237ms/step - loss: 0.6082 - accuracy: 0.7542\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 57s 237ms/step - loss: 0.6221 - accuracy: 0.7250\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6130 - accuracy: 0.7167\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.6064 - accuracy: 0.6958\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 59s 247ms/step - loss: 0.6149 - accuracy: 0.7250\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.6064 - accuracy: 0.7167\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.6178 - accuracy: 0.7333\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 59s 246ms/step - loss: 0.5885 - accuracy: 0.7458\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 59s 248ms/step - loss: 0.6014 - accuracy: 0.7333\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.6180 - accuracy: 0.7250\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.5980 - accuracy: 0.7417\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6014 - accuracy: 0.7208\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 58s 244ms/step - loss: 0.6169 - accuracy: 0.7208\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.6063 - accuracy: 0.7250\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.5968 - accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 58s 240ms/step - loss: 0.5958 - accuracy: 0.7333\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 58s 242ms/step - loss: 0.5927 - accuracy: 0.7125\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 58s 243ms/step - loss: 0.5904 - accuracy: 0.7125\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.5915 - accuracy: 0.7333\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 59s 247ms/step - loss: 0.6060 - accuracy: 0.7417\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 61s 254ms/step - loss: 0.6048 - accuracy: 0.7437\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.5912 - accuracy: 0.7396\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.5875 - accuracy: 0.7417\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 58s 244ms/step - loss: 0.5756 - accuracy: 0.7417\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 61s 255ms/step - loss: 0.5737 - accuracy: 0.7417\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 58s 244ms/step - loss: 0.5961 - accuracy: 0.7417\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 58s 244ms/step - loss: 0.5878 - accuracy: 0.7417\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 59s 245ms/step - loss: 0.6137 - accuracy: 0.7417\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 59s 244ms/step - loss: 0.5881 - accuracy: 0.7417\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 57s 239ms/step - loss: 0.5808 - accuracy: 0.7417\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 58s 241ms/step - loss: 0.5905 - accuracy: 0.7417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x155004decf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train),y_train, epochs=nEpochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 4s 73ms/step\n",
      "Test loss: 0.5339267336931385 / Test Accuracy: 0.7540983557701111\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.array(X_test), y_test, batch_size=3)\n",
    "print(f'Test loss: {score[0]} / Test Accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
